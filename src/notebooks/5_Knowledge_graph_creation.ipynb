{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\53344\\Downloads\\Cases\\Mugen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\53344\\Downloads\\Cases\\Mugen\\mugen\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\53344\\\\Downloads\\\\Cases\\\\Mugen'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\53344\\Downloads\\Cases\\Mugen\\mugen\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO: Process 35812 Shared-Data created for Single Process\n",
      "INFO: Created new empty graph\n",
      "WARNING: No existing Faiss index file found. Starting fresh.\n",
      "WARNING: No existing Faiss index file found. Starting fresh.\n",
      "WARNING: No existing Faiss index file found. Starting fresh.\n",
      "INFO: Process 35812 initialized updated flags for namespace: [full_docs]\n",
      "INFO: Process 35812 ready to initialize storage namespace: [full_docs]\n",
      "INFO: Process 35812 KV load full_docs with 0 records\n",
      "INFO: Process 35812 initialized updated flags for namespace: [text_chunks]\n",
      "INFO: Process 35812 ready to initialize storage namespace: [text_chunks]\n",
      "INFO: Process 35812 KV load text_chunks with 0 records\n",
      "INFO: Process 35812 initialized updated flags for namespace: [entities]\n",
      "INFO: Process 35812 initialized updated flags for namespace: [relationships]\n",
      "INFO: Process 35812 initialized updated flags for namespace: [chunks]\n",
      "INFO: Process 35812 initialized updated flags for namespace: [chunk_entity_relation]\n",
      "INFO: Process 35812 initialized updated flags for namespace: [llm_response_cache]\n",
      "INFO: Process 35812 ready to initialize storage namespace: [llm_response_cache]\n",
      "INFO: Process 35812 KV load llm_response_cache with 0 records\n",
      "INFO: Process 35812 initialized updated flags for namespace: [doc_status]\n",
      "INFO: Process 35812 ready to initialize storage namespace: [doc_status]\n",
      "INFO: Process 35812 doc status load doc_status with 0 records\n",
      "INFO: Process 35812 storage namespace already initialized: [full_docs]\n",
      "INFO: Process 35812 storage namespace already initialized: [text_chunks]\n",
      "INFO: Process 35812 storage namespace already initialized: [llm_response_cache]\n",
      "INFO: Process 35812 storage namespace already initialized: [doc_status]\n",
      "INFO: Process 35812 Pipeline namespace initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Storage Initialization completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, gpt_4o_complete, openai_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "from lightrag.utils import setup_logger, EmbeddingFunc\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "nest_asyncio.apply()\n",
    "\n",
    "setup_logger(\"lightrag\", level=\"INFO\")\n",
    "\n",
    "async def embedding_func(texts: list[str]) -> np.ndarray:\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "    return embeddings\n",
    "\n",
    "async def initialize_rag(directory = \"test\"):\n",
    "    rag = LightRAG(\n",
    "        working_dir=f\"knowledge_graphs/{directory}\",\n",
    "        llm_model_func=gpt_4o_mini_complete,\n",
    "        # embedding_func=openai_embed,\n",
    "        embedding_func=EmbeddingFunc(\n",
    "        embedding_dim=384,\n",
    "        max_token_size=8192,\n",
    "        func=embedding_func,\n",
    "    ),\n",
    "    vector_storage=\"FaissVectorDBStorage\",\n",
    "    vector_db_storage_cls_kwargs={\n",
    "        \"cosine_better_than_threshold\": 0.3  # Your desired threshold\n",
    "    }\n",
    "    )\n",
    "\n",
    "    await rag.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "\n",
    "    return rag\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize RAG instance\n",
    "rag = asyncio.run(initialize_rag())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types= [\"inflation\", \"economy\", \"India\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Inserting 1 records to doc_status\n",
      "INFO: Process 33568 doc status writting 2 records to doc_status\n",
      "INFO: Stored 1 new unique documents\n",
      "INFO: Processing 1 document(s) in 1 batches\n",
      "INFO: Start processing batch 1 of 1.\n",
      "INFO: Inserting 1 records to doc_status\n",
      "INFO: Process 33568 doc status writting 2 records to doc_status\n",
      "INFO: Inserting 42 to chunks\n",
      "INFO: Inserting 1 records to full_docs\n",
      "INFO: Inserting 42 records to text_chunks\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 1/42: extracted 10 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 2/42: extracted 10 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 3/42: extracted 11 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 4/42: extracted 12 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 5/42: extracted 12 entities and 12 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 6/42: extracted 9 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 7/42: extracted 12 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 8/42: extracted 10 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 9/42: extracted 8 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 10/42: extracted 8 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 11/42: extracted 19 entities and 14 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 12/42: extracted 12 entities and 12 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 13/42: extracted 10 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 14/42: extracted 11 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 15/42: extracted 7 entities and 7 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 16/42: extracted 14 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 17/42: extracted 10 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 18/42: extracted 13 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 19/42: extracted 15 entities and 14 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 20/42: extracted 8 entities and 7 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 21/42: extracted 20 entities and 13 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 22/42: extracted 16 entities and 13 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 23/42: extracted 13 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 24/42: extracted 16 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 25/42: extracted 13 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 26/42: extracted 9 entities and 13 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 27/42: extracted 7 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 28/42: extracted 11 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 29/42: extracted 19 entities and 14 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 30/42: extracted 11 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 31/42: extracted 13 entities and 13 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 32/42: extracted 8 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 33/42: extracted 11 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 34/42: extracted 7 entities and 6 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 35/42: extracted 10 entities and 9 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 36/42: extracted 10 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 37/42: extracted 9 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 38/42: extracted 12 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 39/42: extracted 11 entities and 10 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 40/42: extracted 12 entities and 11 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 41/42: extracted 10 entities and 8 relationships (deduplicated)\n",
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO:   Chunk 42/42: extracted 13 entities and 11 relationships (deduplicated)\n",
      "INFO: Process 33568 reloading graph chunk_entity_relation due to update by another process\n",
      "INFO: Extracted 300 entities and 335 relationships (deduplicated)\n",
      "INFO: Inserting 300 to entities\n",
      "INFO: Inserting 335 to relationships\n",
      "INFO: Inserting 1 records to doc_status\n",
      "INFO: Process 33568 doc status writting 2 records to doc_status\n",
      "INFO: Process 33568 KV writting 2 records to full_docs\n",
      "INFO: Process 33568 KV writting 43 records to text_chunks\n",
      "INFO: Process 33568 KV writting 93 records to llm_response_cache\n",
      "INFO: Writing graph with 302 nodes, 335 edges\n",
      "INFO: In memory DB persist to disk\n",
      "INFO: Completed batch 1 of 1.\n",
      "INFO: Document processing pipeline completed\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/mock_data.txt\", encoding =\"utf-8\") as f:\n",
    "    d= f.read()\n",
    "# Insert text\n",
    "rag.insert(d)\n",
    "\n",
    "# Perform naive search\n",
    "mode=\"naive\"\n",
    "# Perform local search\n",
    "mode=\"local\"\n",
    "# Perform global search\n",
    "mode=\"global\"\n",
    "# Perform hybrid search\n",
    "mode=\"hybrid\"\n",
    "# Mix mode Integrates knowledge graph and vector retrieval.\n",
    "mode=\"mix\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Inserting 1 records to llm_response_cache\n",
      "INFO: Process 33568 buidling query context...\n",
      "INFO: Query nodes: Spoon, Fork, Plate, Dal, Chawal, Bhel, top_k: 60, cosine: 0.2\n",
      "INFO: Query edges: Cooking, Food preparation, Meal components, top_k: 60, cosine: 0.2\n",
      "INFO: Process 33568 KV writting 9 records to llm_response_cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sorry, I'm not able to provide an answer to that question.[no-context]\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query= \"What's cooking G? Use Query edges: Spoon, Fork, Plate. Use Query nodes: Dal, Chawal, Bhel. \"\n",
    "rag.query(query,\n",
    "    param=QueryParam(mode=mode),\n",
    "    system_prompt=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pyvis.network.Network'> |N|=302 |E|=335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_graph.html\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode characters in position 263607-263621: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m net\u001b[38;5;241m.\u001b[39mfrom_nx(G)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Save and display the network\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mknowledge_graph.html\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\53344\\Downloads\\Cases\\Mugen\\mugen\\lib\\site-packages\\pyvis\\network.py:546\u001b[0m, in \u001b[0;36mNetwork.show\u001b[1;34m(self, name, local, notebook)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m notebook:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopen_browser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_html(name, open_browser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\53344\\Downloads\\Cases\\Mugen\\mugen\\lib\\site-packages\\pyvis\\network.py:530\u001b[0m, in \u001b[0;36mNetwork.write_html\u001b[1;34m(self, name, local, notebook, open_browser)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdn_resources \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_line\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdn_resources \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremote\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(getcwd_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[1;32m--> 530\u001b[0m         \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcdn_resources is not in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_line\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremote\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\doclayout_yolo\\lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode characters in position 263607-263621: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load the GraphML file\n",
    "G = nx.read_graphml('knowledge_graphs/graph_chunk_entity_relation.graphml')\n",
    "\n",
    "# Create a Pyvis network\n",
    "net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "# Convert NetworkX graph to Pyvis network\n",
    "net.from_nx(G)\n",
    "\n",
    "# Save and display the network\n",
    "# net.show('knowledge_graph.html')\n",
    "\n",
    "html = net.generate_html()\n",
    "with open(\"example.html\", mode='w', encoding='utf-8') as fp:\n",
    "        fp.write(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mugen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
